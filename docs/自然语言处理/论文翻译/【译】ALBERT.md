# 【译】使用深度学习进行答案选择：一个研究及开放性任务

* 作者：Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut
* 论文：《ALBERT: A Lite BERT for Self-supervised Learning of Language Representations》
* 地址：https://arxiv.org/abs/1909.11942


## 摘要

在对自然语言表示进行预处理时，增加模型大小通常会提高下游任务的性能。然而，在某些情况下，由于GPU/TPU内存的限制、更长的训练时间和意料之外的模型退化，使模型的进一步增长会变得更加困难。为了解决这些问题，我们提出了两种参数约简技术（parameter-reduction techniques）来降低内存消耗并提高 BERT 的训练速度(Devlin et al.， 2019)。综合的经验证据表明，我们提出的方法导致模型规模比原来的 BERT 更好。我们还使用了一个自我监督的损失，重点是建立句子间的连贯，并表明它始终有助于下游任务的多句输入。最终结果，我们的最佳模型在 GLUE,RACE 和 SQuAD 基准上建立了新的最优的结果，而参数比 BERT-large 更少。代码和预培训的模型可以在 https://github.com/googl-research/googl-research/tree/master/albert 找到。

## 1. 介绍

全网络预训练(Dai & Le, 2015; Radford等人，2018; Devlin等人，2019; Howard & Ruder,2018)在语言表征学习方面取得了一系列突破。许多非琐碎的NLP任务，包括那些训练数据有限的任务，都从这些预先训练的模型中获益良多。这些突破中最引人注目的一个是中国为初中和高中英语考试设计的阅读理解任务上，机器性能的演变。RACE (ReAding Comprehension dataset collected from English Examinations) 测试(Lai 等, 2017):最初的论文描述了建模的挑战任务,报告了先进的机器精度为44.1%;最新公布的结果显示，他们的模型性能为83.2% (Liu 等, 2019);我们在这里展示的工作将其进一步提高到89.4%，惊人的45.3%的改进，这主要归功于我们当前构建高性能预训练语言表征的能力。

来自这些改进的证据表明，大型网络对于实现最先进的性能至关重要(Devlin 等，2019; Radford 等，2019)。预培训大型模型并将其提炼为小型模型已成为普遍做法(Sun 等， 2019;Turc 等，2019)。考虑到模型大小的重要性，我们问:拥有更好的NLP模型和拥有更大的模型一样容易吗?

回答这个问题的一个障碍是可用硬件的内存限制。考虑到目前最先进的模型通常有数亿甚至数十亿的参数，当我们试图扩展我们的模型时，很容易突破这些限制。在分布式训练中，训练速度也会受到很大的影响，因为通信开销与模型中参数的数量成正比。我们还观察到，简单地增加一个模型的隐层维度大小，比如 BERT-large (Devlin 等， 2019)，会导致更糟糕的性能。表1和图1给出了一个典型的例子，在这个例子中，我们简单地将 BERT-large的隐藏大小增加2倍，而使用这个 BERT-xlarge 模型得到的结果更糟。

[超链接]()

图1：BERT-large 和 BERT-xlarge(在隐层维度大小方面比 BERT-large 大2倍)的训练损失(左)和验证MLM正确率。较大的模型具有较低的 MLM 准确率，但没有明显的过拟合迹象。

Model | Hidden Size | Parameters | RACE (Accuracy) 
-|-|-|-
BERT-large (Devlin et al., 2019) | 1024 | 334M | 72.0% 
BERT-large (ours) | 1024 | 334M | 73.9%
BERT-xlarge (ours) | 2048 | 1270M | 54.3%

表1： 提升 BERT-large 隐层维度大小导致了在 RACE 上更糟的性能

针对上述问题的现有解决方案包括模型并行化(Shoeybi 等， 2019)和智能内存管理(Chen 等，2016; Gomez 等，2017)。这些解决方案解决了内存限制问题，但没有解决通信开销和模型退化问题。在本文中，我们通过设计比传统 BERT 体系结构参数少得多的 A Lite BERT (ALBERT)体系结构来解决所有上述问题。

ALBERT 采用了两种参数约简技术，消除了在缩放预训练模型时的主要障碍。第一个是因式分解 embedding 参数。通过将大的词汇嵌入矩阵分解成两个小的矩阵，将隐藏层的大小与词汇嵌入的大小分离开来。这种分离使得在不显著增加词汇表嵌入的参数大小的情况下更容易地增加隐藏维度的大小。第二种技术是跨层参数共享。这种技术可以防止参数随着网络的深度而增长。这两种方法在不严重影响性能的前提下，显著地减少了BERT的参数数量，从而提高了参数效率。类似于 BERT-large 的 ALBERT 配置参数少了18倍，训练速度快了1.7倍。参数约简技术也作为正则化的一种形式，稳定了训练并有助于泛化。

为了进一步提高ALBERT的性能，我们还引入了一个用于句子顺序预测的自监督损失模型(SOP, sentence-order prediction)。SOP 主要关注句子间的连贯，旨在解决原 BERT 中提出的下一句话预测(NSP)损失(Yang 等， 2019;Liu 等，2019)的无效。

作为这些设计决策的结果，我们能够扩展到更大的 ALBERT 配置，这些配置的参数仍然比 BERT-large 少，但是可以获得更好的性能。我们为自然语言理解在著名的GLUE、SQuAD 和 RACE 基准上建立了新的最先进的结果。具体来说，我们将 RACE 的正确率提高到89.4%，GLUE 基准提高到 89.4,SQuAD的F1提高到92.2。

## 2. 相关工作
### 2.1 扩大自然语言的表征学习

自然语言中学习表征已被证明对广泛的NLP任务有用，并被广泛采用(Mikolov 等， 2013;Le & Mikolov, 2014;Dai & Le，2015;Peters 等，2018;Devlin 人，2019;Radford 等，2018;2019)。过去两年最显著的变化之一是预训练词嵌入的转变，是否标准(Mikolov 等，2013;Pennington 等，2014）或者语境化(McCann 等，2017;Peters 等，2018)，然后是全网络预培训，然后是具体任务的微调(Dai & Le, 2015;Radford等人，2018;Devlin等人，2019)。在这一行工作中，经常可以看到较大的模型大小可以提高性能。例如，Devlin等人(2019)表明，在三个选定的自然语言理解任务中，使用更大的隐藏维度大小、更多的隐藏层和更多的注意力头总是会带来更好的性能。但是，它们的隐藏大小为1024。我们发现，在相同的设置下，将隐藏大小增加到2048会导致模型性能下降，从而导致性能下降。因此，扩大自然语言的表征学习并不像简单地增加模型大小那么容易。

此外，由于计算方面的限制，特别是在GPU/TPU内存方面的限制，大型模型很难进行实验。考虑到目前最先进的模型通常有数亿甚至数十亿的参数，我们很容易突破内存限制。为了解决这个问题，Chen等人(2016)提出了一种称为梯度检查点的方法，以牺牲额外的前向传递为代价，将内存需求降低为次线性。Gomez等人(2017)提出了一种从下一层重建每一层激活的方法，这样它们就不需要存储中间激活。这两种方法都以牺牲速度为代价来减少内存消耗。相比之下，我们的参数约简技术减少了内存消耗，提高了训练速度。

### 2.2 跨层参数共享

跨层共享参数的想法之前已经在Transformer架构中进行了探索(Vaswani等人，2017)，但是之前的工作主要针对标准的编码器和解码器任务进行训练，而不是针对预培训/微调设置的。与我们的观察不同，Dehghani等人(2018)表明，具有跨层参数共享(Universal Transformer, UT)的网络在语言建模和主动词一致方面比标准 Transformer 有更好的性能。最近，Bai等人(2019)提出了一种转换网络的深度均衡模型(Deep Equilibrium Model, DQE)，并证明了DQE可以达到一个平衡点，在这个平衡点上，某个层的输入嵌入和输出嵌入保持不变。我们的观察表明，嵌入是振荡的，而不是收敛的。Hao等人(2019)将参数共享 transformer 与标准 transformer 相结合，进一步增加了标准 transformer 的参数数量。

### 2.3 句子排序目标

ALBERT 使用了一个基于预测两个连续文本片段排序的预训练损失。一些研究人员已经尝试了与话语连贯相关的预训练目标。话语中的连贯和衔接已被广泛研究，并发现了许多连接相邻语段的现象((Hobbs, 1979; Halliday & Hasan, 1976; Grosz 等, 1995)。在实践中发现大多数有效的目标都很简单。Skip-thought (Kiros 等， 2015)和 FastSent  (Hill 等， 2016)通过对句子进行编码来预测相邻句子中的单词来学习句子嵌入。句子嵌入学习的其他目标包括预测将来的句子而不仅仅是邻居(Gan等，2017)和预测显性话语标记(Jernite等，2017;Nie 等人，2019)。我们的损失与Jernite等人(2017)的句子排序目标最为相似，他们通过学习句子嵌入来确定两个连续句子的排序。但是，与上面的大多数工作不同，我们的损失是在文本片段而不是句子中定义的。BERT (Devlin 等， 2019)使用基于预测一对句子中第二段是否与另一个文档中的一段进行了交换的损失。我们在实验中比较了这一损失，发现句子排序是一项更具挑战性的预训练任务，对某些下游任务更有用。在我们的工作同时，Wang等人(2019)也尝试预测两个连续的文本片段的顺序，但他们将其与原始的下一个句子预测结合在一个三分类任务中，而不是从经验上比较两者。

## 3. ALBERT 的元素

在本节中，我们将为 ALBERT 提供设计决策，并与原始 BERT 架构的相应配置进行量化比较(Devlin 等，2019)。

### 3.1 模型架构选择

ALBERT 架构的主干与 BERT 类似，它使用了一个 transformer 编码器(Vaswani 等， 2017)和 GELU 非线性(Hendrycks & Gimpel, 2016)。我们遵循 BERT 符号约定,定义词嵌入大小为 $E$、编码器层的数量为 $L$,和隐藏维度大小为 $H$，遵循 Devlin 等人(2019),我们设置了前馈/过滤器大小为 $4H$,注意力头数为 $H/64$。

ALBERT对BERT的设计的改变上做出了三个主要的贡献。

**因式分解 embedding 参数** 在BERT中，以及随后的建模改进，如 XLNet (Yang 等， 2019)和 RoBERTa (Liu 等， 2019)，词片（WordPiece）嵌入大小 $E$ 与隐层维度大小$H$绑定，即 $E \equiv H$。 对于建模和实际原因，这个决策看起来都不是最优的，如下所示。

从建模的角度来看，词片嵌入意味着学习上下文无关的表征，而隐藏层嵌入意味着学习上下文相关的表示。根据上下文长度的实验表明(Liu 等， 2019)，BERT-like 表征的力量来自于使用上下文为学习这种上下文相关的表征提供信号。因此,解开词片嵌入大小$E$和隐藏层大小$H$,允许我们根据建模需要做出更高效的按需使用的总模型参数,这决定了 $H \gg E$。

从实用的角度来看，自然语言处理通常需要词汇量$V$是大的，如果$E \equiv H$，则增加 $H$ 就增加了具有大小的嵌入矩阵的大小，将具有 $V \times E$ 的大小。这很容易产生一个拥有数十亿参数的模型，其中大多数参数在训练期间只进行少量更新。

因此，对于ALBERT，我们使用嵌入参数的因式分解，将它们分解成两个更小的矩阵。我们不直接将一个 one-hot 向量投影到大小为$H$的隐藏空间中，而是先将其投影到大小为$E$的低维嵌入空间中，然后再将其投影到隐藏空间中。通过使用这种分解,我们将嵌入参数从$O(V \times H)$减少到了 $O(V\times E+E\times H)$。当$H\gg E$时，这个参数显著减少，我们选择对所有的词片使用相同的$E$,因为与整词嵌入相比他们更均匀分布在文档中,有不同的嵌入大小(Grave 等。(2017);Baevski & Auli (2018);Dai 等.(2019)))对于不同的单词来说是重要的。

**跨层参数共享** 对于 ALBERT，我们提出了一种跨层参数共享的方法来提高参数效率。共享参数的方法有多种，例如只跨层共享前馈网络(FFN)参数，或只共享注意力参数。ALBERT的默认决策是跨层共享所有参数。除非另有说明，我们所有的实验都使用这个默认决策。

Dehghani 等 (2018) (Universal Transformer, UT)和 Bai 等. (2019) (Deep Equilibrium Models, DQE)对 Transformer 网络也探索了类似的策略。与我们的观察不同，Dehghani等人(2018)表明UT性能优于香草 Transformer。Bai等(2019)的研究表明，他们的DQEs达到了一个平衡点，在这个平衡点上，某一层的输入和输出嵌入保持不变。我们对 L2 距离和余弦相似度的测量表明，我们的嵌入是振荡的，而不是收敛的。

[超链接]()

图2： BERT-large 和 ALBERT-large 各层嵌入的输入和输出的L2距离和余弦相似度(以度表示)。

图2显示了使用 BERT-large 和 ALBERT-large 配置的每一层的输入和输出嵌入的L2距离和余弦相似度(见表2)。结果表明，权值共享对网络参数的稳定有一定的影响。尽管与BERT相比，这两个指标都有下降，但即使在24层之后，它们也不会收敛到0。这说明ALBERT参数的解空间与DQE的解空间有很大的不同。

**句间连贯性损失** 除了遮蔽语言建模(MLM)损失(Devlin 等， 2019)之外，BERT还使用了一个称为下一句话预测(NSP)的额外损失。NSP是预测两个片段在原文中是否连续出现的二分类损失，具体如下:从训练语料库中提取连续片段，生成正例;负例是由来自不同文档的片段配对产生的;正、负样本的抽样概率相等。NSP的目标是为了提高下游任务的性能，比如自然语言推理，这需要对句子对之间的关系进行推理。然而，后续研究(Yang 等，2019;Liu等人2019)发现NSP的影响不可靠，并决定消除它，这一决定得到了多个任务的下游任务性能改进的支持。

我们推测，NSP之所以无效的主要原因是它作为一项任务缺乏难度，与MLM相比。NSP将主题预测和相干性预测合并在一起作为单一的任务。然而，与一致性预测相比，主题预测更容易学习，并且与使用MLM损失所学的内容有更多的重叠。

我们认为句间建模是语言理解的一个重要方面，但我们提出了一个主要基于连贯的损失。也就是说，对于ALBERT来说，我们使用了一个句子顺序预测损失(SOP)，它避免了主题预测，而是专注于对句子间连贯性进行建模。SOP损失使用与BERT相同的技术作为正例(同一文档中的两个连续片段)，而作为负例使用相同的两个连续段，但顺序互换。这就迫使模型学习关于话语级连贯性属性的更细粒度的区别。如第4.6节所示，NSP根本无法解决SOP任务(即，它最终学习更容易的主题预测信号，并在SOP任务上执行随机基线水平)，而SOP可以在分析未对齐的相干线索的基础上，预先将NSP任务解决到一个合理的程度。因此，ALBERT模型不断地改进多句编码任务的下游任务性能。

### 3.2 模型设置

表2给出了 BERT 和 ALBERT 模型在超参数设置上的差异。由于以上讨论的设计选择，ALBERT 模型的参数尺寸比相应的 BERT 模型要小得多。

Model | Parameters | Layers | Hidden | Embedding | Parameter-sharing
-|-|-|-|-|-
BERT base | 108M | 12 | 768 | 768 | False
BERT large | 334M | 24 | 1024 | 1024 | False
BERT xlarge | 1270M | 24 | 2048 | 2048 | False
ALBERT base | 12M | 12 | 768 | 128 | True
ALBERT large | 18M | 24 | 1024 | 128 | True
ALBERT xlarge | 60M | 24 | 2048 | 128 | True
ALBERT xxlarge | 235M | 12 | 4096 | 128 | True

表2：本文对主要的BERT和ALBERT模型的结构进行分析的配置。

例如，与 BERT-large 相比，ALBERT-large少了大约18倍的参数，前者是18M，后者是334M。如果我们将 BERT 设置为超大规模，$H=2048$,我们最终得到一个拥有12.7亿的模型参数和低性能(图1)。相比之下,一个 ALBERT-xlarge 配置$H=2048$只有60M参数,而一个 ALBERT-xxlarge 配置$H =4096$有 233M 参数,即约70%的 BERT-large 参数。注意，对于 ALBERT-xxlarge，我们主要在12层网络上报告结果，因为24层网络(具有相同的配置)可以获得类似的结果，但在计算上更昂贵。

这种参数效率的提高是ALBERT设计选择的最重要的优势。在我们能够量化这一优势之前，我们需要更详细地介绍我们的实验设置。

## 4 实验结果
### 4.1 实验设置

为了使比较尽可能有意义，我们遵循 BERT (Devlin 等，2019)设置，使用 BookCorpus 语料库(Zhu 等，2015)和英语维基百科(Devlin 等，2019)进行预训练基线模型。这两个语料库由大约16GB的未压缩文本组成。我们的格式化我们的输入为“[CLS] $x_1$[SEP]$x_2$[SEP]”，其中$x_1=x_{1,1},x_{1,2} \cdots$,$x_2=x_{2,1},x_{2,2}\cdots$是两段。我们总是限制最大输入长度为512，以10%的概率随机产生输入序列小于512的句子。和BERT一样，我们使用了30000个词汇量，用句片来标记(Kudo & Richardson, 2018)，比如XLNet (Yang 等， 2019)。

我们使用 n-gram 遮蔽(Joshi 等，2019)为MLM目标生成遮蔽输入，随机选择每个n-gram掩码的长度。长度为$n$的概率由下式给出：

$$
p(n)=\frac{1/n}{\sum_{k=1}^N 1/k}
$$

我们设置了n-gram的最大长度(即，n)为3(即，MLM目标可以由一个3-gram完整的单词，比如“White House correspondents”)。

所有的模型更新都使用批大小为4096和学习率为0.00176的LAMB优化器(You 等，2019)。除非另有说明，我们对所有型号进行125,000步的训练。训练是在 Cloud TPU V3上完成的。根据模型的大小，用于训练的TPUs的数量从64到1024不等。

本节中描述的实验设置用于我们自己的 BERT 和 ALBERT 模型的所有版本，除非另有说明。

### 4.2 评价基准

#### 4.2.1 内在(固有)评估

为了监控训练进度，我们使用与第4.1节相同的步骤，创建了一个基于来自 SQuAD 和 RACE 的开发集的开发集。我们报告准确的MLM和句子分类任务。注意，我们只使用这个集合来检查模型是如何收敛的;它的使用方式不会影响任何下游评估的性能，例如通过模型选择。


#### 4.2.2 下游评价

在Yang等人(2019)和Liu等人(2019)之后，我们在三个流行的基准上评估我们的模型:通用语言理解评估(GLUE)基准(Wang等人，2018)、两个版本的斯坦福问答数据集(SQuAD;Rajpurkar等人，2016;2018)以及来自考试(RACE)数据集的阅读理解(Lai 等，2017)。为了完整性，我们在附录A.1中提供了对这些基准的描述。与(Liu等人，2019年)一样，我们在开发集上执行早期停止，除了基于任务排行榜的最终比较之外，我们报告所有的比较，我们还报告测试集结果。

### 4.3 BERT和ALBERT的总体比较

<!-- 我们现在准备量化第3节中描述的设计选择的影响，特别是关于参数效率的选择。参数的改善效率展示最重要的利用 BERT 的设计选择,如表3所示:只有BERT-large大约70%的参数,在BERT-large ALBERT-xxlarge达到显著改善,以发展组分数的区别几个代表下游任务:球队v1.1(+ 1.7%),球队v2.0 (+ 4.2%), MNLI (+ 2.2%), SST-2(+ 3.0%),和种族(+ 8.5%)。

我们还观察到，在所有指标上，bet -xlarge得到的结果明显比bet -base差。这表明，像BERT-xlarge这样的模型比那些参数大小较小的模型更难训练。另一个有趣的发现是，在相同的训练配置(相同数量的TPUs)下，训练时的数据吞吐量的速度。由于艾伯特模型通信少、计算量小，与对应的伯特模型相比，艾伯特模型具有更高的数据吞吐量。最慢的是BERT-xlarge模型，我们使用它作为基线。随着模型的增大，BERT和ALBERT模型之间的差异也越来越大，例如ALBERT-xlarge训练速度是BERT-xlarge的2.4倍。 -->

---
**参考**：
1. 论文：Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942)（2019.10.23）
